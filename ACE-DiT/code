# AR-DiT

import torch
import torch.nn as nn

# 1. CNN Feature Extractor
class CNNFeatureExtractor(nn.Module):
    def __init__(self, output_size):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),  # Input: 3 channels (RGB)
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * 56 * 56, output_size),  # For 224x224 input image
            nn.ReLU()
        )
    
    def forward(self, image):
        """Process an image and return a feature vector."""
        return self.features(image)

# 2. Basis Model
class BasisModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.linear = nn.Linear(input_dim, output_dim)
    
    def forward(self, x):
        """Apply a linear transformation to the input."""
        return self.linear(x)

# 3. AdaptiveRemix-DiT Model
class AdaptiveRemixDiT(nn.Module):
    def __init__(self, n_basis, n_experts, input_dim, output_dim, cnn_output_size):
        super().__init__()
        self.n_basis = n_basis
        self.n_experts = n_experts
        # List of basis models
        self.basis_models = nn.ModuleList([BasisModel(input_dim, output_dim) for _ in range(n_basis)])
        # Learnable base mixing coefficients
        self.base_mixing_coeffs = nn.Parameter(torch.randn(n_experts, n_basis))
        # CNN for adaptive coefficient adjustment
        self.cnn = CNNFeatureExtractor(cnn_output_size)
        # Linear layer to map CNN output to coefficient adjustments
        self.cnn_conditioning = nn.Linear(cnn_output_size, n_experts * n_basis)
    
    def create_expert(self, coeffs):
        """Create an expert by linearly combining basis models with given coefficients."""
        expert = nn.Linear(
            self.basis_models[0].linear.in_features,
            self.basis_models[0].linear.out_features
        )
        with torch.no_grad():
            expert.weight = sum(
                coeff * basis.linear.weight for coeff, basis in zip(coeffs, self.basis_models)
            )
            expert.bias = sum(
                coeff * basis.linear.bias for coeff, basis in zip(coeffs, self.basis_models)
            )
        return expert
    
    def forward(self, x, image):
        """Forward pass with CNN-adjusted mixing coefficients."""
        # Extract features from the image using CNN
        cnn_output = self.cnn(image)
        # Compute adjustments to mixing coefficients
        delta_alpha = self.cnn_conditioning(cnn_output).view(self.n_experts, self.n_basis)
        # Adjust base mixing coefficients
        adjusted_mixing_coeffs = self.base_mixing_coeffs + delta_alpha
        # Create experts with adjusted coefficients
        experts = [self.create_expert(adjusted_mixing_coeffs[i]) for i in range(self.n_experts)]
        # Use the first expert for simplicity (can be extended to use all experts)
        return experts[0](x)

# 4. Example Usage
def main():
    # Hyperparameters
    n_basis = 4          # Number of basis models
    n_experts = 20       # Number of experts
    input_dim = 10       # Input dimension for Remix-DiT
    output_dim = 10      # Output dimension for Remix-DiT
    cnn_output_size = 512  # Size of CNN feature vector

    # Instantiate the model
    model = AdaptiveRemixDiT(n_basis, n_experts, input_dim, output_dim, cnn_output_size)

    # Sample inputs
    image = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 channels, 224x224 image
    x = torch.randn(1, input_dim)        # Input vector to Remix-DiT

    # Forward pass
    output = model(x, image)
    print(f"Output shape: {output.shape}")  # Expected: [1, 10]

if __name__ == "__main__":
    main()
